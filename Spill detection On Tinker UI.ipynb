{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368e115c-8551-4e86-a524-9609193c30bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 30.7/43.6 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 725.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/9.3 MB 12.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.2/9.3 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.3 MB 27.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.2/9.3 MB 27.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.0/9.3 MB 25.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.3 MB 26.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.3 MB 28.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 27.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "   ---------------------------------------- 0.0/402.6 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 184.3/402.6 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 402.6/402.6 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp39-cp39-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.0/269.0 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 287.9/287.9 kB 17.4 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.4/2.2 MB 44.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.4 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.42.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32026238-4c6d-4fc1-9999-176b11d830d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:3101: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd49abbe1394c81a3cbfd0861ad6388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\auto\\processing_auto.py:221: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "\n",
    "model_id = \"google/paligemma-3b-mix-224\"\n",
    "token = \"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\"\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id,use_auth_token='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')\n",
    "processor = AutoProcessor.from_pretrained(model_id,use_auth_token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ac4f37-6593-4086-89f4-3e18d8b889d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import Image\n",
    "from twilio.rest import Client\n",
    "import threading\n",
    "import torch\n",
    "\n",
    "# Your Twilio credentials\n",
    "account_sid = 'AC8faa1d1b34626cd229aa3848ee2ebd63'\n",
    "auth_token = 'c75e51379c543a5c63f4b7718609f65f'\n",
    "\n",
    "# Initialize the Twilio client\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "def process_image(file_path):\n",
    "    prompt = \"Is there any spill in image?\"\n",
    "    raw_image = Image.open(file_path)\n",
    "\n",
    "    inputs = processor(prompt, raw_image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "    result = processor.decode(output[0], skip_special_tokens=True)[len(prompt):].strip()\n",
    "    return result\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        result_label.config(text=\"Processing...\", fg=\"blue\")\n",
    "        threading.Thread(target=process_and_notify, args=(file_path,)).start()\n",
    "\n",
    "def process_and_notify(file_path):\n",
    "    result = process_image(file_path)\n",
    "    root.after(0, update_ui, result)\n",
    "\n",
    "    if result == 'yes':\n",
    "        message = client.messages.create(\n",
    "            body='''############ Alert ############\n",
    "    Please Check the Ware House facility in Zone-1 area. There is a Oil spill.''',\n",
    "            from_='whatsapp:+14155238886',  # Twilio phone number\n",
    "            to= 'whatsapp:+919016939348' # Recipient's phone number\n",
    "        )\n",
    "        root.after(0, messagebox.showinfo, \"Notification\", f\"Spill detected! Message sent with SID: {message.sid}\")\n",
    "    else:\n",
    "        root.after(0, messagebox.showinfo, \"Result\", \"No spill detected.\")\n",
    "\n",
    "def update_ui(result):\n",
    "    result_label.config(text=f\"Result: {result}\", fg=\"green\" if result.lower() == 'yes' else \"red\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Spill Detection\")\n",
    "root.geometry(\"400x400\")\n",
    "root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# Create a frame to center align all elements\n",
    "frame = tk.Frame(root, bg=\"#f0f0f0\")\n",
    "frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n",
    "\n",
    "# Add a title label\n",
    "title_label = tk.Label(frame, text=\"Spill Detection System\", bg=\"#f0f0f0\", font=(\"Helvetica\", 20, \"bold\"))\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "# Add an instruction label\n",
    "instruction_label = tk.Label(frame, text=\"Upload an image to check for any spills. The system will notify if a spill is detected.\", \n",
    "                             bg=\"#f0f0f0\", font=(\"Helvetica\", 12), wraplength=350)\n",
    "instruction_label.pack(pady=10)\n",
    "\n",
    "# Create a button to upload an image\n",
    "upload_button = tk.Button(frame, text=\"Upload Image\", command=upload_image, bg=\"#4CAF50\", fg=\"white\", font=(\"Helvetica\", 15, \"bold\"))\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Create a label to show the result\n",
    "result_label = tk.Label(frame, text=\"Result: \", bg=\"#f0f0f0\", font=(\"Helvetica\", 17))\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Add a footer label\n",
    "footer_label = tk.Label(frame, text=\" Project by Team Nirmaan \", bg=\"#f0f0f0\", font=(\"Helvetica\", 10, \"italic\"))\n",
    "footer_label.pack(pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
